# PRODPLAN 4.0 OS - CONTEXTO COMPLETO DO PROJETO

> **âš ï¸ IMPORTANTE**: Este documento foi atualizado apÃ³s inspeÃ§Ã£o dos headers REAIS do Excel e implementaÃ§Ã£o completa do backend PostgreSQL-only.
> Ver `CORRECTIONS_FROM_REAL_HEADERS.md`, `POSTGRES_BOOTSTRAP_FINAL.md`, `FINAL_POSTGRES_BOOTSTRAP.md` para detalhes das correÃ§Ãµes e implementaÃ§Ãµes.

## ğŸ“‹ ÃNDICE

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [PostgreSQL-Only Architecture](#postgresql-only-architecture)
3. [Arquitetura do Sistema](#arquitetura-do-sistema)
4. [Modelo de Dados](#modelo-de-dados)
5. [Fluxo de Dados](#fluxo-de-dados)
6. [IngestÃ£o Turbo](#ingestÃ£o-turbo)
7. [Componentes Principais](#componentes-principais)
8. [Stack TecnolÃ³gico](#stack-tecnolÃ³gico)
9. [PrincÃ­pios de Design](#princÃ­pios-de-design)
10. [Estrutura do Projeto](#estrutura-do-projeto)
11. [Endpoints da API](#endpoints-da-api)
12. [Jobs e Processos](#jobs-e-processos)
13. [Observabilidade](#observabilidade)
14. [Deployment e Bootstrap](#deployment-e-bootstrap)
15. [ValidaÃ§Ã£o e Testes](#validaÃ§Ã£o-e-testes)
16. [DecisÃµes Arquiteturais](#decisÃµes-arquiteturais)
17. [CorreÃ§Ãµes e ValidaÃ§Ãµes](#correÃ§Ãµes-e-validaÃ§Ãµes)

---

## ğŸ¯ VISÃƒO GERAL

**PRODPLAN 4.0 OS** Ã© um sistema backend de produÃ§Ã£o para planeamento e otimizaÃ§Ã£o de fabrico industrial. O sistema processa dados reais de produÃ§Ã£o a partir de um ficheiro Excel (`Folha_IA.xlsx`) e fornece:

- **VisualizaÃ§Ã£o** de ordens de fabrico e fases
- **SimulaÃ§Ã£o** de cenÃ¡rios (WHAT-IF)
- **AnÃ¡lise de qualidade** e risco de defeitos
- **PrevisÃµes ML** de lead time
- **MonitorizaÃ§Ã£o** de WIP (Work In Progress)
- **KPIs** e mÃ©tricas de performance
- **DetecÃ§Ã£o de gargalos** e filas de risco

### Fonte de Dados

- **Ficheiro**: `Folha_IA.xlsx`
- **9 Sheets** com ~1.1M linhas totais:
  - OrdensFabrico: 27,380 ordens
  - FasesOrdemFabrico: 519,079 fases
  - FuncionariosFaseOrdemFabrico: 423,769 atribuiÃ§Ãµes
  - OrdemFabricoErros: 89,836 erros
  - Funcionarios: 902 funcionÃ¡rios
  - FuncionariosFasesAptos: 902 aptidÃµes
  - Fases: 71 fases
  - Modelos: 894 produtos
  - FasesStandardModelos: 15,348 rotas padrÃ£o

### ValidaÃ§Ã£o de Headers Reais

Todos os headers foram validados atravÃ©s do **Inspector** (`app/ingestion/inspector.py`), que gera:
- `DATA_DICTIONARY.md` - Schema completo com headers reais
- `PROFILE_REPORT.json` - AnÃ¡lise detalhada (null rates, cardinalidade, tipos)
- `RELATIONSHIPS_REPORT.json` - Match rates de relacionamentos FK

**Match Rates CrÃ­ticos Identificados**:
- `FuncionarioFaseOf_FaseOfId â†” FaseOf_Id`: **32.3%** âŒ â†’ NÃƒO suporta produtividade por funcionÃ¡rio
- `Produto_Id â†” Of_ProdutoId`: **72.5%** âš ï¸ â†’ 339 orphans (reportar, nÃ£o rejeitar)

---

## ğŸ—„ï¸ POSTGRESQL-ONLY ARCHITECTURE

### Requisitos ObrigatÃ³rios

**PostgreSQL 15+ Ã© OBRIGATÃ“RIO** - SQLite nÃ£o Ã© suportado.

O sistema foi projetado para usar exclusivamente PostgreSQL devido a features especÃ­ficas:
- `PARTITION BY RANGE` / `PARTITION BY HASH` - Particionamento declarativo
- Ãndices com `INCLUDE` - Para evitar heap fetches
- `UNLOGGED` tables - Para staging tables rÃ¡pidas
- `MATERIALIZED VIEW CONCURRENTLY` - Refresh sem locks
- Features avanÃ§adas: JSONB, arrays, window functions

### ValidaÃ§Ãµes Fail-Fast

1. **backend/config.py**
   - RuntimeError se DATABASE_URL nÃ£o existe
   - RuntimeError se DATABASE_URL Ã© SQLite
   - RuntimeError se scheme nÃ£o Ã© postgresql/postgresql+psycopg2
   - Mensagens exatas: "DATABASE_URL is required. PostgreSQL 15+ only. SQLite is not supported."

2. **alembic/env.py**
   - Valida PostgreSQL antes de executar migrations
   - RuntimeError com mensagens exatas
   - NÃ£o permite SQLite "por acidente"

3. **tests/conftest.py**
   - PostgreSQL-only (nÃ£o SQLite)
   - Skip com mensagem clara se PostgreSQL nÃ£o disponÃ­vel
   - Cleanup via transaÃ§Ãµes (PostgreSQL-specific)

### Bootstrap Automatizado

**Comando Ãºnico para setup completo**:
```bash
./scripts/bootstrap_postgres.sh
```

Este script:
1. Inicia PostgreSQL via Docker (`docker compose up -d db`)
2. Aguarda PostgreSQL ficar ready (pg_isready loop, timeout 120s)
3. Aplica migrations (`alembic upgrade head`)
4. Valida prÃ©-requisitos (`python scripts/validate_prerequisites.py`)
5. Roda release gate (`python scripts/release_gate.py`)

**ValidaÃ§Ãµes**:
- `scripts/validate_prerequisites.py`: Valida versÃ£o PostgreSQL >= 15 (obrigatÃ³rio)
- `scripts/release_gate.py`: Bloqueia release se falhar, escreve `docs/RELEASE_BLOCKED.md`

---

## ğŸ—ï¸ ARQUITETURA DO SISTEMA

### Diagrama de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (React/Vite)                     â”‚
â”‚              (NÃƒO MODIFICADO - Backend Only)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ HTTP/REST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASTAPI API SERVER                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  PRODPLAN    â”‚  â”‚   WHAT-IF    â”‚  â”‚   QUALITY    â”‚     â”‚
â”‚  â”‚   Service    â”‚  â”‚   Service    â”‚  â”‚   Service    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚SmartInventoryâ”‚  â”‚     ML       â”‚  â”‚   Ops        â”‚     â”‚
â”‚  â”‚   Service    â”‚  â”‚  Predictor   â”‚  â”‚ (Metrics)    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚  Bottlenecks â”‚  â”‚     KPIs     â”‚                       â”‚
â”‚  â”‚   Service    â”‚  â”‚   Service    â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚Postgresâ”‚   â”‚   Redis   â”‚  â”‚  Prometheusâ”‚  â”‚  Arq     â”‚
â”‚  15+   â”‚   â”‚  (Cache)  â”‚  â”‚ (Metrics)  â”‚  â”‚ (Worker) â”‚
â”‚        â”‚   â”‚  (Locks)  â”‚  â”‚            â”‚  â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â†’ core.* (tabelas finais com constraints, partiÃ§Ãµes)
    â”œâ”€â†’ staging.*_raw (UNLOGGED, sem FKs, para ingestÃ£o rÃ¡pida)
    â”œâ”€â†’ agg_* (agregados incrementais)
    â””â”€â†’ *_rejects (quarentena de dados invÃ¡lidos)
```

### Fluxo de Dados Principal

```
Excel (Folha_IA.xlsx)
    â†“
[Inspector] â†’ DATA_DICTIONARY.md, PROFILE_REPORT.json, RELATIONSHIPS_REPORT.json
    â†“
[Extract] â†’ CSV.gz (streaming, openpyxl read_only=True)
    â†“
[Load] â†’ staging.*_raw (COPY FROM STDIN, UNLOGGED)
    â†“
[Validate] â†’ *_rejects (dados invÃ¡lidos)
    â†“
[Merge] â†’ core.* (INSERT ... ON CONFLICT DO UPDATE, idempotente)
    â†“
[Backfill] â†’ Colunas derivadas (faseof_event_time, ofch_event_time, etc.)
    â†“
[Reconcile] â†’ Resolver Ã³rfÃ£os FK
    â†“
[Aggregates] â†’ agg_phase_stats_daily, agg_order_stats_daily, etc.
    â†“
[MVs Refresh] â†’ Materialized Views (incremental)
    â†“
[Cache Invalidation] â†’ Redis cache version increment
```

---

## ğŸ“Š MODELO DE DADOS

### Tabelas Core (com constraints, partiÃ§Ãµes, Ã­ndices)

#### 1. `core.ordens_fabrico`
- **PK**: `of_id`
- **Colunas**: `of_data_criacao`, `of_data_acabamento`, `of_produto_id`, `of_fase_id`, `of_data_transporte`
- **Ãndices**:
  - `idx_of_produto_data`: `(of_produto_id, of_data_criacao DESC, of_id DESC)`
  - `idx_of_fase`: `(of_fase_id)`
  - `idx_of_datas`: `(of_data_criacao, of_data_acabamento)`
  - `idx_of_transporte`: `(of_data_transporte)` WHERE `of_data_transporte IS NOT NULL`

#### 2. `core.fases_ordem_fabrico` (PARTICIONADA)
- **PK**: `faseof_id`
- **Particionamento**: `PARTITION BY RANGE (faseof_event_time)` - PartiÃ§Ãµes mensais
- **Colunas**:
  - Base: `faseof_of_id`, `faseof_inicio`, `faseof_fim`, `faseof_data_prevista`, `faseof_coeficiente`, `faseof_coeficiente_x`, `faseof_fase_id`, `faseof_turno`, `faseof_retorno`, `faseof_peso`, `faseof_sequencia`
  - Derivadas (governadas): `faseof_event_time`, `faseof_duration_seconds`, `faseof_is_open`, `faseof_is_done`
- **Ãndices**:
  - `idx_faseof_ofid_event`: `(faseof_of_id, faseof_event_time)`
  - `idx_faseof_faseid_event`: `(faseof_fase_id, faseof_event_time)`
  - `idx_faseof_open_by_fase`: `(faseof_fase_id, faseof_of_id)` WHERE `faseof_is_open = true`

#### 3. `core.funcionarios_fase_ordem_fabrico` (PARTICIONADA)
- **PK**: `(funcionariofaseof_id, funcionario_id)`
- **Particionamento**: `PARTITION BY HASH (funcionariofaseof_id)` - 32 partiÃ§Ãµes
- **Colunas**: `funcionariofaseof_id`, `funcionario_id`, `chefe`
- **Nota**: Match rate baixo (32.3%) â†’ nÃ£o suporta KPIs por funcionÃ¡rio

#### 4. `core.erros_ordem_fabrico` (PARTICIONADA)
- **PK**: `ofch_id`
- **Particionamento**: `PARTITION BY HASH (ofch_of_id)` - 32 partiÃ§Ãµes
- **Colunas**:
  - Base: `ofch_descricao_erro`, `ofch_of_id`, `ofch_fase_avaliacao`, `ofch_faseof_culpada`, `ofch_faseof_avaliacao`, `ofch_gravidade`
  - Derivada: `ofch_event_time` (backfill via join)

#### 5. Tabelas de CatÃ¡logo
- `core.fases_catalogo`: `fase_id`, `fase_nome`
- `core.modelos`: `produto_id`, `produto_nome`, `produto_peso_desmolde`, `produto_peso_acabamento`, `produto_qtd_gel_deck`, `produto_qtd_gel_casco`
- `core.fases_standard_modelos`: `produto_id`, `fase_id`, `sequencia`, `coeficiente`, `coeficiente_x`
- `core.funcionarios`: `funcionario_id`, `funcionario_nome`, `funcionario_activo`
- `core.funcionarios_fases_aptos`: `funcionario_id`, `fase_id`, `data_criacao`

### Tabelas Staging (UNLOGGED, sem FKs)

- `staging.ordens_fabrico_raw`
- `staging.fases_ordem_fabrico_raw`
- `staging.funcionarios_fase_ordem_fabrico_raw`
- `staging.erros_ordem_fabrico_raw`
- (e outras...)

### Tabelas de Agregados Incrementais

- `agg_phase_stats_daily`: EstatÃ­sticas diÃ¡rias por fase/produto
- `agg_order_stats_daily`: Lead time e on-time rate
- `agg_quality_daily`: Qualidade por produto/fase
- `agg_wip_current`: WIP atual (tabela incremental)

### Tabelas de Suporte

- `ingestion_runs`: Auditoria de execuÃ§Ãµes
- `ingestion_sheet_runs`: Auditoria por sheet
- `*_rejects`: Quarentena de dados invÃ¡lidos
- `data_quality_issues`: Anomalias/Ã³rfÃ£os/duplicados
- `analytics_watermarks`: Rastreamento de Ãºltima processamento
- `ops_cache_version`: VersÃ£o global de cache
- `whatif_runs`: PersistÃªncia de simulaÃ§Ãµes
- `model_registry`: VersÃµes de modelos ML

---

## ğŸ”„ INGESTÃƒO TURBO

### Pipeline em 3 Fases

#### Fase 1: Extract
- **Script**: `app/ingestion/extract.py`
- **Processo**: 
  - Ler Excel com `openpyxl` (read_only=True, data_only=False)
  - Iterar por linhas (streaming)
  - Converter para CSV.gz por sheet
  - Normalizar datas (ISO-8601), decimais, preservar NULLs
  - Calcular checksum SHA256 por sheet

#### Fase 2: Load
- **Script**: `app/ingestion/load.py`
- **Processo**:
  - PostgreSQL `COPY FROM STDIN` para staging.*_raw
  - Batches de 50k linhas
  - ConfiguraÃ§Ã£o de sessÃ£o:
    - `synchronous_commit=off`
    - `maintenance_work_mem=512MB`
    - `work_mem=64MB`
  - UNLOGGED tables para velocidade

#### Fase 3: Merge
- **Script**: `app/ingestion/merge.py`
- **Processo**:
  - `INSERT ... ON CONFLICT DO UPDATE` de staging para core
  - DeduplicaÃ§Ã£o por chave natural
  - Popular colunas derivadas
  - Popular rejects para linhas invÃ¡lidas

### ValidaÃ§Ã£o e Quarentena

- **Validators**: `app/ingestion/validators.py`
  - ValidaÃ§Ã£o de tipos, ranges, constraints
  - RejeiÃ§Ã£o de dados invÃ¡lidos para `*_rejects`
- **Reconciliation**: Job pÃ³s-carga para resolver Ã³rfÃ£os FK
- **Count Validation**: `app/ingestion/validate_counts.py`
  - Valida contagens vs Excel
  - Gera `docs/CRITICAL_MISMATCHES.md` se houver diferenÃ§as

### IdempotÃªncia

- `ingestion_runs` guarda:
  - `run_id`, `started_at`, `finished_at`
  - `excel_sha256`, `per_sheet_sha256`
  - `rows_extracted`, `rows_loaded`, `rows_merged`, `rows_rejected`
- Se `excel_sha256` nÃ£o mudou â†’ NO-OP (ou revalidaÃ§Ã£o)
- `ON CONFLICT DO UPDATE` mantÃ©m consistÃªncia

---

## ğŸ§© COMPONENTES PRINCIPAIS

### ServiÃ§os de NegÃ³cio

#### 1. PRODPLAN Service (`app/services/prodplan.py`)
- Estado de OF (CREATED, IN_PROGRESS, DONE, LATE, AT_RISK)
- Timeline por OF (`/orders/{of_id}/phases`)
- Baseline de planeamento por produto (`/routes/{produto_id}`)
- KPIs: lead time, throughput, on-time rate, WIP aging
- **Bottlenecks**: DetecÃ§Ã£o de gargalos (`/api/prodplan/bottlenecks`)
- **Risk Queue**: Filas de risco operacional (`/api/prodplan/risk_queue`)

#### 2. WHAT-IF Service (`app/services/whatif.py`)
- SimulaÃ§Ã£o determinÃ­stica com seed fixa
- Inputs: priority_rule, capacity_overrides, coef_overrides
- Outputs: baseline_kpis, simulated_kpis, delta_kpis, top_affected_orders
- PersistÃªncia: `whatif_runs` com hash do cenÃ¡rio

#### 3. QUALITY/ZDM Service (`app/services/quality.py`)
- Overview: total_erros, erros_por_gravidade, erros_por_fase
- Taxa por produto: erro_rate_produto
- Heatmap: avaliaÃ§Ã£o vs culpada
- Risco baseline: probabilidade histÃ³rica por produto/fase

#### 4. SmartInventory Service (`app/services/smartinventory.py`)
- WIP por fase e produto
- WIP mass: estimativa de massa em processo
- Gelcoat theoretical usage: consumo teÃ³rico (nÃ£o real)
- Retorna `NOT_SUPPORTED_BY_DATA` quando dados insuficientes

#### 5. Bottlenecks Service (`app/services/bottlenecks.py`)
- DetecÃ§Ã£o de gargalos por fase
- WIP age p90, queue size
- Fases com maior risco operacional

### ML/PyTorch

#### Datasets
- `app/ml/datasets/build_leadtime.py`: Dataset para regressÃ£o de lead time
- `app/ml/datasets/build_defect_risk.py`: Dataset para classificaÃ§Ã£o de risco

#### Training
- `app/ml/training/train_leadtime.py`: Treino de modelo de lead time
- Baseline determinÃ­stico obrigatÃ³rio
- Splits temporais (treino/validaÃ§Ã£o/teste)
- MÃ©tricas: MAE, MAPE, p90_error

#### Prediction
- `app/ml/prediction/predictor.py`: InferÃªncia de modelos
- Fallback para baseline se modelo nÃ£o disponÃ­vel
- XAI: SHAP ou permutation importance

### Analytics

#### Incremental Aggregates (`app/analytics/incremental_aggregates.py`)
- ComputaÃ§Ã£o incremental usando watermarks
- Tabelas: `agg_phase_stats_daily`, `agg_order_stats_daily`, `agg_quality_daily`, `agg_wip_current`
- Refresh apenas janela "new data since watermark"

#### Materialized Views
- `mv_phase_durations_by_model`: DuraÃ§Ãµes por modelo/fase
- `mv_order_leadtime_by_model`: Lead time por modelo
- `mv_quality_by_phase`: Qualidade por fase
- `mv_wip_by_phase_current`: WIP atual por fase

### Operations

#### Cache (`app/ops/cache.py`)
- Redis com versioning global (`ops_cache_version`)
- Singleflight: evita cache stampede
- InvalidaÃ§Ã£o automÃ¡tica apÃ³s ingestÃ£o/backfill/aggregate refresh
- TTL: schedule/current 20-30s, kpis/overview 60s

#### Metrics (`app/ops/metrics.py`)
- Prometheus metrics
- InstrumentaÃ§Ã£o: ingestion, queries, cache, ML

#### Tracing (`app/ops/tracing.py`)
- OpenTelemetry tracing
- HTTP + DB instrumentation

#### Rate Limiting (`app/ops/rate_limit.py`)
- Redis-based rate limiting
- Por IP e API key
- ProteÃ§Ã£o de endpoints write/high-cost

#### Authentication (`app/auth/api_key.py`)
- API key authentication (`X-API-Key`)
- ProteÃ§Ã£o de endpoints: `/api/ingestion/run`, `/api/ml/train/*`, `/api/whatif/simulate`

---

## ğŸ› ï¸ STACK TECNOLÃ“GICO

### Backend
- **Python 3.11+**
- **FastAPI**: Web framework
- **SQLAlchemy 2.x**: ORM
- **Alembic**: Migrations
- **PostgreSQL 15+**: Database (obrigatÃ³rio, sem SQLite)
- **Redis**: Cache, locks distribuÃ­dos, rate limiting
- **Arq**: Async job queue
- **openpyxl**: Excel reading (read_only, streaming)

### Observabilidade
- **Prometheus**: Metrics
- **OpenTelemetry**: Tracing
- **structlog**: JSON logging

### ML
- **PyTorch**: Deep learning
- **scikit-learn**: Baseline models
- **SHAP**: Explainability
- **joblib**: Model serialization

### DevOps
- **Docker Compose**: Local deployment
- **PostgreSQL 15-alpine**: Database container
- **Redis 7-alpine**: Cache container

---

## ğŸ¯ PRINCÃPIOS DE DESIGN

### P0. Data-First
- Cada feature mapeia explicitamente para colunas reais do Excel
- Sem mocks, sem placeholders, sem dados sintÃ©ticos

### P1. Streaming Everywhere
- NÃ£o carregar sheets enormes para RAM
- IteraÃ§Ã£o por linhas, batches controlados

### P2. ObservÃ¡vel
- Logs estruturados (JSON)
- MÃ©tricas Prometheus
- Tracing OpenTelemetry

### P3. Idempotente
- IngestÃ£o e jobs incrementais nunca duplicam
- `ON CONFLICT DO UPDATE` para merges

### P4. DeterminÃ­stico
- KPIs e resultados replicÃ¡veis
- Seeds fixas para ML e simulaÃ§Ãµes

### P5. Fail Fast + Quarantine
- Dados invÃ¡lidos â†’ `*_rejects` com motivo
- NÃ£o corrigir silenciosamente

### P6. Performance by Design
- Ãndices compostos, partiÃ§Ãµes, MVs
- Caches, agregados incrementais
- Keyset pagination (nÃ£o OFFSET)

### P7. PostgreSQL-Only
- Zero fallbacks SQLite
- ValidaÃ§Ãµes fail-fast
- RuntimeError se SQLite detectado

---

## ğŸ“ ESTRUTURA DO PROJETO

```
nelo/
â”œâ”€â”€ alembic/
â”‚   â”œâ”€â”€ versions/
â”‚   â”‚   â”œâ”€â”€ 001_initial_schema_with_partitioning.py
â”‚   â”‚   â”œâ”€â”€ 002_materialized_views.py
â”‚   â”‚   â”œâ”€â”€ 003_corrected_schema_from_real_headers.py
â”‚   â”‚   â”œâ”€â”€ 004_incremental_aggregates_and_watermarks.py
â”‚   â”‚   â””â”€â”€ 005_indexes_with_include.py
â”‚   â”œâ”€â”€ env.py
â”‚   â””â”€â”€ script.py.mako
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ analytics/
â”‚   â”‚   â””â”€â”€ incremental_aggregates.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routers/
â”‚   â”‚       â”œâ”€â”€ bottlenecks.py
â”‚   â”‚       â”œâ”€â”€ ingestion.py
â”‚   â”‚       â”œâ”€â”€ kpis.py
â”‚   â”‚       â”œâ”€â”€ ml.py
â”‚   â”‚       â”œâ”€â”€ prodplan.py
â”‚   â”‚       â”œâ”€â”€ quality.py
â”‚   â”‚       â”œâ”€â”€ smartinventory.py
â”‚   â”‚       â””â”€â”€ whatif.py
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â””â”€â”€ api_key.py
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ batch_upsert.py
â”‚   â”‚   â”œâ”€â”€ extract.py
â”‚   â”‚   â”œâ”€â”€ inspector.py
â”‚   â”‚   â”œâ”€â”€ load.py
â”‚   â”‚   â”œâ”€â”€ main_turbo.py
â”‚   â”‚   â”œâ”€â”€ mappers.py
â”‚   â”‚   â”œâ”€â”€ merge.py
â”‚   â”‚   â”œâ”€â”€ orchestrator_turbo.py
â”‚   â”‚   â”œâ”€â”€ validate_counts.py
â”‚   â”‚   â””â”€â”€ validators.py
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”‚   â”œâ”€â”€ build_defect_risk.py
â”‚   â”‚   â”‚   â””â”€â”€ build_leadtime.py
â”‚   â”‚   â”œâ”€â”€ prediction/
â”‚   â”‚   â”‚   â””â”€â”€ predictor.py
â”‚   â”‚   â””â”€â”€ training/
â”‚   â”‚       â””â”€â”€ train_leadtime.py
â”‚   â”œâ”€â”€ ops/
â”‚   â”‚   â”œâ”€â”€ cache.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â”œâ”€â”€ rate_limit.py
â”‚   â”‚   â””â”€â”€ tracing.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ bottlenecks.py
â”‚   â”‚   â”œâ”€â”€ data_quality.py
â”‚   â”‚   â”œâ”€â”€ prodplan.py
â”‚   â”‚   â”œâ”€â”€ quality.py
â”‚   â”‚   â”œâ”€â”€ smartinventory.py
â”‚   â”‚   â””â”€â”€ whatif.py
â”‚   â””â”€â”€ workers/
â”‚       â”œâ”€â”€ jobs_aggregates.py
â”‚       â”œâ”€â”€ jobs_backfill.py
â”‚       â”œâ”€â”€ jobs_partitions.py
â”‚       â”œâ”€â”€ jobs.py
â”‚       â””â”€â”€ worker.py
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ database.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ Folha_IA.xlsx
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ ingestion_report.json
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ perf/
â”‚   â””â”€â”€ RELEASE_BLOCKED.md (se release gate falhar)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ bootstrap_postgres.sh
â”‚   â”œâ”€â”€ release_gate.py
â”‚   â””â”€â”€ validate_prerequisites.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ performance/
â”‚   â”‚   â””â”€â”€ test_slos.py
â”‚   â”œâ”€â”€ test_data_quality.py
â”‚   â”œâ”€â”€ test_integrity.py
â”‚   â””â”€â”€ test_services_corrected.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ requirements.txt
â””â”€â”€ PROJECT_CONTEXT.md (este arquivo)
```

---

## ğŸŒ ENDPOINTS DA API

### Ingestion
- `POST /api/ingestion/run` - Rodar ingestÃ£o turbo (API key required)
- `GET /api/ingestion/status/{run_id}` - Status da ingestÃ£o
- `GET /api/ingestion/report/{run_id}` - RelatÃ³rio da ingestÃ£o

### PRODPLAN
- `GET /api/prodplan/orders` - Lista de ordens (keyset pagination)
- `GET /api/prodplan/orders/{of_id}` - Detalhe de ordem
- `GET /api/prodplan/orders/{of_id}/phases` - Timeline de fases
- `GET /api/prodplan/routes/{produto_id}` - Roteiro padrÃ£o do produto
- `GET /api/prodplan/schedule/current` - Schedule atual (WIP)
- `GET /api/prodplan/bottlenecks` - DetecÃ§Ã£o de gargalos
- `GET /api/prodplan/risk_queue` - Filas de risco operacional

### KPIs
- `GET /api/kpis/overview` - Overview de KPIs
- `GET /api/kpis/by-phase` - KPIs por fase
- `GET /api/kpis/by-product` - KPIs por produto
- `GET /api/kpis/by-employee` - KPIs por funcionÃ¡rio (condicional, retorna NOT_SUPPORTED_BY_DATA se match rate < 90%)

### QUALITY
- `GET /api/quality/overview` - Overview de qualidade
- `GET /api/quality/by-phase` - Qualidade por fase
- `GET /api/quality/by-product` - Qualidade por produto
- `GET /api/quality/risk` - Risco de defeito

### WHAT-IF
- `POST /api/whatif/simulate` - Simular cenÃ¡rio (API key required)
- `GET /api/whatif/result/{whatif_id}` - Resultado da simulaÃ§Ã£o

### SmartInventory
- `GET /api/smartinventory/wip` - WIP por fase/produto
- `GET /api/smartinventory/wip_mass` - Massa em processo
- `GET /api/smartinventory/gelcoat_theoretical_usage` - Uso teÃ³rico de gelcoat

### ML
- `POST /api/ml/train/leadtime` - Treinar modelo de lead time (API key required)
- `POST /api/ml/train/risk` - Treinar modelo de risco (API key required)
- `GET /api/ml/models` - Lista de modelos
- `POST /api/ml/predict/leadtime` - Prever lead time
- `POST /api/ml/predict/risk` - Prever risco
- `GET /api/ml/explain/leadtime` - Explicar previsÃ£o de lead time
- `GET /api/ml/explain/risk` - Explicar previsÃ£o de risco

### Ops
- `GET /api/health` - Health check
- `GET /metrics` - Prometheus metrics

---

## âš™ï¸ JOBS E PROCESSOS

### Jobs Incrementais (Arq)

#### Backfill Jobs (`app/workers/jobs_backfill.py`)
- `backfill_ofch_event_time`: Popular `ofch_event_time` via join
- `backfill_faseof_derived_columns`: Popular colunas derivadas de fases

#### Aggregate Jobs (`app/workers/jobs_aggregates.py`)
- `compute_aggregates_incremental`: Computar agregados incrementais
- `refresh_mvs_incremental`: Refresh materialized views incremental

#### Partition Jobs (`app/workers/jobs_partitions.py`)
- `ensure_partitions_ahead`: Criar partiÃ§Ãµes futuras (6 meses)
- `partition_health_report`: RelatÃ³rio de saÃºde de partiÃ§Ãµes

### Jobs Principais (`app/workers/jobs.py`)
- `ingestion_run`: Executar ingestÃ£o
- `reconcile`: ReconciliaÃ§Ã£o pÃ³s-carga
- `refresh_mvs_incremental`: Refresh MVs
- `compute_kpi_snapshots_incremental`: Computar snapshots de KPIs
- `ml_train_nightly`: Treino ML noturno (opcional)

### Watermarks

- `analytics_watermarks`: Rastreamento de Ãºltima processamento
  - `last_processed_of_acabamento`
  - `last_processed_faseof_fim`
  - `last_processed_error_backfill`
  - `last_kpi_snapshot_date`
  - `last_model_train_cutoff`

---

## ğŸ“Š OBSERVABILIDADE

### Logs
- **Formato**: JSON (structlog)
- **Campos**: `run_id`, `sheet`, `entity`, `rows`, `duration_ms`, `error_code`, `correlation_id`

### MÃ©tricas Prometheus
- `ingestion_rows_total{sheet, status}`
- `ingestion_duration_seconds{sheet}`
- `db_query_duration_seconds{endpoint, query_name}`
- `cache_hits_total{endpoint}`
- `cache_misses_total{endpoint}`
- `whatif_runs_total`
- `ml_inference_duration_seconds{model}`
- `ml_train_duration_seconds{task}`

### Tracing
- OpenTelemetry instrumentation
- HTTP + DB spans
- Correlation IDs

---

## ğŸš€ DEPLOYMENT E BOOTSTRAP

### Bootstrap Automatizado

**Comando Ãºnico**:
```bash
./scripts/bootstrap_postgres.sh
```

**Ou via Makefile**:
```bash
make bootstrap
```

### Docker Compose

**ServiÃ§os**:
- `db`: PostgreSQL 15-alpine (porta 5432)
- `redis`: Redis 7-alpine (porta 6379)
- `api`: FastAPI server (porta 8000)
- `worker`: Arq worker
- `prometheus`: Prometheus (porta 9090)
- `grafana`: Grafana (porta 3000)

**Healthchecks**:
- `db`: `pg_isready -U nelo_user -d nelo_db -h localhost` (interval: 2s, timeout: 2s, retries: 60)

### VariÃ¡veis de Ambiente

Criar `.env` a partir de `.env.example`:
```
DATABASE_URL=postgresql://nelo_user:nelo_pass@localhost:5432/nelo_db
REDIS_URL=redis://localhost:6379/0
FOLHA_IA_PATH=./data/raw/Folha_IA.xlsx
API_KEY=dev-key-change-in-production
REQUIRE_API_KEY=false
CORS_ORIGINS=http://localhost:5174,http://localhost:3000
```

### ValidaÃ§Ã£o de PrÃ©-requisitos

```bash
python scripts/validate_prerequisites.py
```

Valida:
- DATABASE_URL existe e Ã© PostgreSQL
- VersÃ£o PostgreSQL >= 15
- ConexÃ£o funciona
- Excel file existe

### Release Gate

```bash
python scripts/release_gate.py
```

Valida:
- Schema e migrations aplicadas
- Tabelas core existem
- PartiÃ§Ãµes criadas
- IngestÃ£o completa (se rodada)
- Performance benchmarks (se existirem)
- Feature gating

Se falhar, escreve `docs/RELEASE_BLOCKED.md` com razÃ£o e aÃ§Ã£o recomendada.

---

## âœ… VALIDAÃ‡ÃƒO E TESTES

### Testes de Integridade

- `tests/test_integrity.py`: ValidaÃ§Ãµes de integridade
  - Datas coerentes (faseof_fim >= faseof_inicio)
  - FKs vÃ¡lidas
  - DomÃ­nios (gravidade, etc.)

### Testes de Qualidade de Dados

- `tests/test_data_quality.py`: ValidaÃ§Ãµes de qualidade
  - Match rates
  - Feature gating
  - NOT_SUPPORTED_BY_DATA

### Testes de ServiÃ§os

- `tests/test_services_corrected.py`: Testes de serviÃ§os corrigidos
  - ProdplanService
  - QualityService
  - SmartInventoryService

### Testes de Performance

- `tests/performance/test_slos.py`: ValidaÃ§Ã£o de SLOs
  - `/orders` p95 < 400ms
  - `/orders/{id}` p95 < 250ms
  - `/schedule/current` p95 < 250ms
  - `/kpis/overview` p95 < 300ms

### EXPLAIN Plans

- Guardados em `docs/perf/EXPLAIN_{endpoint}.md`
- Gerados com `EXPLAIN (ANALYZE, BUFFERS)`

---

## ğŸ¯ DECISÃ•ES ARQUITETURAIS

### 1. PostgreSQL-Only (Sem SQLite)

**DecisÃ£o**: Remover completamente SQLite, usar apenas PostgreSQL 15+

**RazÃ£o**:
- Migrations usam features especÃ­ficas (PARTITION BY, INCLUDE, UNLOGGED, MVs CONCURRENTLY)
- Performance e escalabilidade
- ConsistÃªncia entre dev e produÃ§Ã£o

**ImplementaÃ§Ã£o**:
- RuntimeError se SQLite detectado
- ValidaÃ§Ã£o em `backend/config.py`, `alembic/env.py`, `tests/conftest.py`
- Bootstrap script valida PostgreSQL >= 15

### 2. Staging + Core Tables

**DecisÃ£o**: Separar staging (UNLOGGED, sem FKs) de core (com constraints)

**RazÃ£o**:
- IngestÃ£o rÃ¡pida via COPY em staging
- ValidaÃ§Ã£o antes de merge
- IdempotÃªncia via ON CONFLICT

### 3. Particionamento

**DecisÃ£o**: Particionar tabelas grandes (fases_ordem_fabrico, erros_ordem_fabrico, funcionarios_fase_ordem_fabrico)

**RazÃ£o**:
- Performance em queries por data
- ManutenÃ§Ã£o facilitada (DROP partiÃ§Ã£o antiga)
- Pruning automÃ¡tico

### 4. Aggregados Incrementais

**DecisÃ£o**: Tabelas de agregados incrementais + watermarks, em vez de apenas MVs

**RazÃ£o**:
- Refresh incremental mais rÃ¡pido
- Evita REFRESH MATERIALIZED VIEW full
- Watermarks permitem processar apenas novos dados

### 5. Cache Versionado

**DecisÃ£o**: Cache Redis com versioning global

**RazÃ£o**:
- InvalidaÃ§Ã£o eficiente (incrementar versÃ£o)
- Singleflight evita cache stampede
- ConsistÃªncia garantida

### 6. Feature Gating

**DecisÃ£o**: Desativar features dinamicamente baseado em match rates

**RazÃ£o**:
- Evitar resultados enganosos
- TransparÃªncia sobre limitaÃ§Ãµes dos dados
- Exemplo: `by_employee` retorna NOT_SUPPORTED_BY_DATA se match rate < 90%

---

## ğŸ”§ CORREÃ‡Ã•ES E VALIDAÃ‡Ã•ES

### CorreÃ§Ãµes Baseadas em Headers Reais

1. **Colunas renomeadas**:
   - `modelo_id` â†’ `produto_id` (consistÃªncia)
   - `ofch_*` columns (corrigidas de `erro_*`)

2. **Colunas adicionadas**:
   - `faseof_sequencia` (detectada no Excel)
   - `produto_qtd_gel_*` (corrigidas de `produto_gelcoat_*`)

3. **Match Rates Validados**:
   - `FuncionarioFaseOf_FaseOfId â†” FaseOf_Id`: 32.3% â†’ NÃƒO suporta produtividade
   - `Produto_Id â†” Of_ProdutoId`: 72.5% â†’ 339 orphans (reportar)

### ValidaÃ§Ãµes Implementadas

1. **Count Validation**: Valida contagens vs Excel, gera `CRITICAL_MISMATCHES.md` se diferente
2. **Release Gate**: ValidaÃ§Ã£o completa antes de release
3. **Prerequisites**: Valida PostgreSQL, versÃ£o, conexÃ£o, Excel file

---

## ğŸ“š DOCUMENTAÃ‡ÃƒO ADICIONAL

- `README_PRODUCTION.md`: Guia operacional completo
- `POSTGRES_ONLY.md`: DocumentaÃ§Ã£o PostgreSQL-only
- `EXECUTION_GUIDE.md`: Guia de execuÃ§Ã£o passo a passo
- `app/ingestion/DATA_DICTIONARY.md`: Schema completo gerado automaticamente
- `app/ingestion/INGESTION_GUIDE.md`: Guia de ingestÃ£o
- `docs/perf/README.md`: DocumentaÃ§Ã£o de performance

---

**Ãšltima atualizaÃ§Ã£o**: 2025-12-17
**VersÃ£o**: 4.0 OS (PostgreSQL-Only, Production-Ready)
